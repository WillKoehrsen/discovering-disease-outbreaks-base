{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are parts of this Notebook that will be executed (Or not) based on this flag\n",
    "debug = False\n",
    "\n",
    "## Imports\n",
    "from unidecode import unidecode # To remove accents and stuff from texts\n",
    "import re                       #Regular expression library\n",
    "import geonamescache            # For database of places on earth\n",
    "from hashlib import md5         # Used to generate unique dictionary keys for the lines\n",
    "import numpy as np              # for array manipulation\n",
    "import pandas                   # Final resut needs to be in this format\n",
    "import json                     # For saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example list of headlines with data:\n",
      " [{'line': 'Zika Outbreak Hits Miami', 'place': 'Miami', 'country': nan, 'places': ['Miami']}, {'line': 'Could Zika Reach New York City?', 'place': 'New York City', 'country': nan, 'places': ['York', 'New York City', 'New York']}, {'line': 'First Case of Zika in Miami Beach', 'place': 'Miami Beach', 'country': nan, 'places': ['Miami', 'Miami Beach']}, {'line': 'Mystery Virus Spreads in Recife, Brazil', 'place': 'Recife', 'country': 'Brazil', 'places': ['Recife']}, {'line': 'Dallas man comes down with case of Zika', 'place': 'Dallas', 'country': nan, 'places': ['Dallas']}]\n"
     ]
    }
   ],
   "source": [
    "export_json='../data/found_cities.json'\n",
    "with open(export_json, 'r') as checkJSONDump:\n",
    "    jsonData=json.loads(checkJSONDump.read())\n",
    "print(\"Example list of headlines with data:\\n\",jsonData[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization of city names\n",
    "\n",
    "Many of the names in the geonamescache database have their names with accents and non ASCII characters.\n",
    "\n",
    "In order to make search easier, I \"normalize\" the names in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc = geonamescache.GeonamesCache()\n",
    "cities = gc.get_cities()\n",
    "\n",
    "# 'Normalize' names of cities in order to make search more accurate\n",
    "for id, city in list(cities.items()):\n",
    "    cities[id]['normalized'] = unidecode(city['name']).lower()\n",
    "\n",
    "if debug:\n",
    "    export_json='../data/all_cities.json'\n",
    "    with open(export_json, 'w') as openJSON:\n",
    "        openJSON.write(json.dumps(gc.get_cities(), indent=4, sort_keys=True))\n",
    "    export_json='../data/all_countries.json'\n",
    "    with open(export_json, 'w') as openJSON:\n",
    "        openJSON.write(json.dumps(gc.get_countries(), indent=4, sort_keys=True))\n",
    "    export_json='../data/all_continents.json'\n",
    "    with open(export_json, 'w') as openJSON:\n",
    "        openJSON.write(json.dumps(gc.get_continents(), indent=4, sort_keys=True))\n",
    "    print(dir(gc))\n",
    "if debug:\n",
    "    for id, city in list(cities.items())[:10]:\n",
    "        print(city['name'], cities[id]['normalized'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "I used the following 3 helpe functions in this notebook:\n",
    "\n",
    "`get_cities_by_name` uses the DB of city names but use the normalized value. As the data from the previous notebook had those cleaned of accents and non ASCII characters this was needed in order to have better accuracy when searching.\n",
    "\n",
    "`extract_city_data` function to add the required data to headlines.\n",
    "\n",
    "`get_city_by_key` this function finds a city in the genoamescache DB by geonameid instead of name. This function is used when there is more than one city with the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cities_by_name(name, dataset, debug = False):\n",
    "    found = {}\n",
    "    if debug:\n",
    "        print('Starting searching', name)\n",
    "    nameLow = unidecode(name).lower()\n",
    "    for id, city in dataset.items():\n",
    "        if debug:\n",
    "            print('Testing id', id, city['name'], ',', city['normalized'], ', >>')\n",
    "        if nameLow == city['name'] or nameLow == city['normalized']:\n",
    "            found[id] = city\n",
    "    if not found:\n",
    "        return []\n",
    "    return [found]\n",
    "if debug:\n",
    "    dbgCities = get_cities_by_name('springfield', cities)\n",
    "    for element in dbgCities[0].items():\n",
    "        print(json.dumps(element))\n",
    "\n",
    "def extract_city_data(cities, headline):\n",
    "    for cid, city in cities.items():\n",
    "        headline['place']=city['name']\n",
    "        headline['lat']=city['latitude']\n",
    "        headline['lng']=city['longitude']\n",
    "        headline['countrycode']=city['countrycode']\n",
    "    return headline\n",
    "\n",
    "def get_city_by_key(geoid, name):\n",
    "    list = get_cities_by_name(name, cities)\n",
    "    if geoid in list[0]:\n",
    "        cities_wrapper = {}\n",
    "        cities_wrapper[geoid] = list[0][geoid]\n",
    "        return cities_wrapper\n",
    "    return ('More than one found', list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of cities found once: 432\n",
      "amount of cities found more than once: 170\n"
     ]
    }
   ],
   "source": [
    "allFoundCities = 0\n",
    "allFoundDuplicatedCities = 0\n",
    "\n",
    "# We search the city in the genames cache and...\n",
    "for headline in jsonData:\n",
    "    if not headline['place']:\n",
    "        continue\n",
    "    foundCities = get_cities_by_name(headline['place'], cities)\n",
    "    # The city is not found.\n",
    "    if len(foundCities) < 1:\n",
    "        continue;\n",
    "    #There's exactly one city. Extract the relevant data (Latitude, longitude, countrycode)\n",
    "    if len(foundCities[0].keys()) == 1:\n",
    "        allFoundCities = allFoundCities +1\n",
    "        headline = extract_city_data(foundCities[0], headline)\n",
    "        continue\n",
    "    # There's more than one city found. We add the needed fienls to headlines but empty as placeholders\n",
    "    dupcities = []\n",
    "    for cid, _city in foundCities[0].items():\n",
    "        dupcities.append(_city)\n",
    "    headline['lat'] = 0\n",
    "    headline['lng'] = 0\n",
    "    headline['countrycode'] = np.NaN\n",
    "    headline['list_of_cities'] = dupcities\n",
    "    allFoundDuplicatedCities = allFoundDuplicatedCities + 1\n",
    "            \n",
    "print(\"Amount of cities found once:\", allFoundCities)\n",
    "print(\"amount of cities found more than once:\", allFoundDuplicatedCities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for headline in jsonData:\n",
    "    if 'list_of_cities' in headline:\n",
    "        # -The existance of this property indicates that we found more than one city with this name\n",
    "        maxPop=0\n",
    "        geoid=0\n",
    "        nonUS = False\n",
    "        country = ''\n",
    "        for city in headline['list_of_cities']:\n",
    "            # We find the city with the biggest population and use that one for the data\n",
    "            if city['population'] > maxPop:\n",
    "                maxPop = city['population']\n",
    "                geoid = str(city['geonameid'])\n",
    "                country = city['countrycode']\n",
    "            if city['countrycode'] != 'US':\n",
    "                nonUS = True\n",
    "        if nonUS:\n",
    "            isUS = \"There is a city from another country than US here\"\n",
    "        else:\n",
    "            isUS = ''\n",
    "        if nonUS and country == \"US\":\n",
    "            isUS = isUS + \" but we chose an US city.\"\n",
    "        else:\n",
    "            isUS = '.'\n",
    "        selectedCity = get_city_by_key(geoid, headline['place'])\n",
    "        headline = extract_city_data(selectedCity, headline)\n",
    "        #headline['countrycode'] = selectedCity['countrycode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = gc.get_countries()\n",
    "for headline in jsonData:\n",
    "    if 'countrycode' not in headline:\n",
    "        continue\n",
    "    if headline['countrycode'] not in countries:\n",
    "        print(\"Country code\", headline['countrycode'], \"not found in list of countries:\", headline['place'])\n",
    "        continue\n",
    "    headline['country'] = countries[headline['countrycode']]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>countrycode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>Zika Outbreak Hits Miami</td>\n",
       "      <td>Miami</td>\n",
       "      <td>25.77427</td>\n",
       "      <td>-80.19366</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>Could Zika Reach New York City?</td>\n",
       "      <td>New York City</td>\n",
       "      <td>40.71427</td>\n",
       "      <td>-74.00597</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>First Case of Zika in Miami Beach</td>\n",
       "      <td>Miami Beach</td>\n",
       "      <td>25.79065</td>\n",
       "      <td>-80.13005</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>Mystery Virus Spreads in Recife, Brazil</td>\n",
       "      <td>Recife</td>\n",
       "      <td>-8.05389</td>\n",
       "      <td>-34.88111</td>\n",
       "      <td>BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>Dallas man comes down with case of Zika</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>32.78306</td>\n",
       "      <td>-96.80667</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>Trinidad confirms first Zika case</td>\n",
       "      <td>Trinidad</td>\n",
       "      <td>-14.83333</td>\n",
       "      <td>-64.90000</td>\n",
       "      <td>BO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>Zika Concerns are Spreading in Houston</td>\n",
       "      <td>Houston</td>\n",
       "      <td>29.76328</td>\n",
       "      <td>-95.36327</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>Geneve Scientists Battle to Find Cure</td>\n",
       "      <td>Genève</td>\n",
       "      <td>46.20222</td>\n",
       "      <td>6.14569</td>\n",
       "      <td>CH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>The CDC in Atlanta is Growing Worried</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>33.74900</td>\n",
       "      <td>-84.38798</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>Zika Infested Monkeys in Sao Paulo</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>-23.54750</td>\n",
       "      <td>-46.63611</td>\n",
       "      <td>BR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 headline           city  latitude  longitude  \\\n",
       "                 Zika Outbreak Hits Miami          Miami  25.77427  -80.19366   \n",
       "          Could Zika Reach New York City?  New York City  40.71427  -74.00597   \n",
       "        First Case of Zika in Miami Beach    Miami Beach  25.79065  -80.13005   \n",
       "  Mystery Virus Spreads in Recife, Brazil         Recife  -8.05389  -34.88111   \n",
       "  Dallas man comes down with case of Zika         Dallas  32.78306  -96.80667   \n",
       "        Trinidad confirms first Zika case       Trinidad -14.83333  -64.90000   \n",
       "   Zika Concerns are Spreading in Houston        Houston  29.76328  -95.36327   \n",
       "    Geneve Scientists Battle to Find Cure         Genève  46.20222    6.14569   \n",
       "    The CDC in Atlanta is Growing Worried        Atlanta  33.74900  -84.38798   \n",
       "       Zika Infested Monkeys in Sao Paulo      São Paulo -23.54750  -46.63611   \n",
       "\n",
       " countrycode  \n",
       "          US  \n",
       "          US  \n",
       "          US  \n",
       "          BR  \n",
       "          US  \n",
       "          BO  \n",
       "          US  \n",
       "          CH  \n",
       "          US  \n",
       "          BR  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert headlines to pandas dataframe\n",
    "headlinesArray = []\n",
    "for headline in jsonData:\n",
    "    #print(headline)\n",
    "    if 'lat' not in headline:\n",
    "        continue\n",
    "    headlinesArray.append([headline['line'], headline['place'], headline['lat'], headline['lng'], headline['countrycode']])\n",
    "df = pandas.DataFrame(headlinesArray, columns = ['headline', 'city', 'latitude', 'longitude', 'countrycode'])#.reset_index(drop=True)\n",
    "blankIndex=[''] * len(df)\n",
    "df.index=blankIndex\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the data found as JSON file\n",
    "export_json='../data/found_cities_locations.json'\n",
    "with open(export_json, 'w') as openJSON:\n",
    "    openJSON.write(json.dumps(list(jsonData)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'line': 'Zika Outbreak Hits Miami', 'place': 'Miami', 'country': 'United States', 'places': ['Miami'], 'lat': 25.77427, 'lng': -80.19366, 'countrycode': 'US'}, {'line': 'Could Zika Reach New York City?', 'place': 'New York City', 'country': 'United States', 'places': ['York', 'New York City', 'New York'], 'lat': 40.71427, 'lng': -74.00597, 'countrycode': 'US'}, {'line': 'First Case of Zika in Miami Beach', 'place': 'Miami Beach', 'country': 'United States', 'places': ['Miami', 'Miami Beach'], 'lat': 25.79065, 'lng': -80.13005, 'countrycode': 'US'}, {'line': 'Mystery Virus Spreads in Recife, Brazil', 'place': 'Recife', 'country': 'Brazil', 'places': ['Recife'], 'lat': -8.05389, 'lng': -34.88111, 'countrycode': 'BR'}, {'line': 'Dallas man comes down with case of Zika', 'place': 'Dallas', 'country': 'United States', 'places': ['Dallas'], 'lat': 32.78306, 'lng': -96.80667, 'countrycode': 'US', 'list_of_cities': [{'geonameid': 4684888, 'name': 'Dallas', 'latitude': 32.78306, 'longitude': -96.80667, 'countrycode': 'US', 'population': 1300092, 'timezone': 'America/Chicago', 'admin1code': 'TX', 'normalized': 'dallas'}, {'geonameid': 5722064, 'name': 'Dallas', 'latitude': 44.91928, 'longitude': -123.31705, 'countrycode': 'US', 'population': 15277, 'timezone': 'America/Los_Angeles', 'admin1code': 'OR', 'normalized': 'dallas'}]}]\n"
     ]
    }
   ],
   "source": [
    "with open(export_json, 'r') as checkJSONDump:\n",
    "    json_test=json.loads(checkJSONDump.read())\n",
    "print(json_test[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
